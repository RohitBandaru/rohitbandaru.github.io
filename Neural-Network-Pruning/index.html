<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="4zEwdc_gZtK7GAY69eUGNqwH6-hIgaXtASEwUuEDEho"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Pruning Neural Networks | Rohit Bandaru </title> <meta name="author" content="Rohit Bandaru"> <meta name="description" content="ML blog. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta property="og:site_name" content="Rohit Bandaru"> <meta property="og:type" content="website"> <meta property="og:title" content="Rohit Bandaru | Pruning Neural Networks"> <meta property="og:url" content="https://rohitbandaru.github.io/blog/Neural-Network-Pruning/"> <meta property="og:description" content="ML blog. "> <meta property="og:image" content="ü§ñ"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="Pruning Neural Networks"> <meta name="twitter:description" content="ML blog. "> <meta name="twitter:image" content="ü§ñ"> <meta name="twitter:site" content="@rohit_bandaru"> <meta name="twitter:creator" content="@rohit_bandaru"> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Rohit Bandaru"
        },
        "url": "https://rohitbandaru.github.io/blog/Neural-Network-Pruning/",
        "@type": "WebSite",
        "description": "ML blog.
",
        "headline": "Pruning Neural Networks",
        
        "sameAs": ["https://www.linkedin.com/in/rohit-bandaru", "https://twitter.com/rohit_bandaru"],
        
        "name": "Rohit Bandaru",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/blog/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%96&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://rohitbandaru.github.io/blog/Neural-Network-Pruning/"> <script src="/blog/assets/js/theme.js?bd888c560287cd675855c7662a167c4a"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/blog/"> <span class="font-weight-bold">Rohit</span> Bandaru </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/about/">about </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Pruning Neural Networks</h1> <p class="post-meta"> Created in September 01, 2020 </p> <p class="post-tags"> <i class="fa-solid fa-calendar fa-sm"></i> 2020 ¬† ¬∑ ¬† <i class="fa-solid fa-hashtag fa-sm"></i> applied-ml </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Much of the success of deep learning has come from building larger and larger neural networks. This allows these models to perform better on various tasks, but also makes them more expensive to use. Larger models take more storage space which makes them harder to distribute. Larger models also take more time to run and can require more expensive hardware. This is especially a concern if you are productionizing a model for a real-world application.</p> <p>Model compression aims to reduce the size of models while minimizing loss in accuracy or performance. Neural network pruning is a method of compression that involves removing weights from a trained model. In agriculture, pruning is cutting off unnecessary branches or stems of a plant. In machine learning, pruning is removing unnecessary neurons or weights. We will go over some basic concepts and methods of neural network pruning.</p> <h1 id="remove-weights-or-neurons">Remove weights or neurons?</h1> <p>There are different ways to prune a neural network.</p> <ol> <li>You can prune weights.</li> </ol> <p>This is done by setting individual parameters to zero and making the network sparse. This would lower the number of parameters in the model while keeping the architecture the same.</p> <ol> <li>You can remove entire nodes from the network.</li> </ol> <p>This would make the network architecture itself smaller, while aiming to keep the accuracy of the initial larger network.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/assets/img/blog/pruning/weights_vs_neurons-480.webp 480w,/blog/assets/img/blog/pruning/weights_vs_neurons-800.webp 800w,/blog/assets/img/blog/pruning/weights_vs_neurons-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/blog/assets/img/blog/pruning/weights_vs_neurons.png" width="100%" height="auto" alt="pruning weights vs nodes" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption"> Visualization of pruning weights/synapses vs nodes/neurons <a href="https://arxiv.org/abs/1506.02626" rel="external nofollow noopener" target="_blank"> Source </a> </figcaption> </figure> <p>Weight-based pruning is more popular as it is easier to do without hurting the performance of the network. However, it requires sparse computations to be effective. This requires hardware support and a certain amount of sparsity to be efficient. Pruning nodes will allow dense computation which is more optimized. This allows the network to be run normally without sparse computation. This dense computation is more often better supported on hardware. However, removing entire neurons can more easily hurt the accuracy of the neural network.</p> <h1 id="what-to-prune">What to prune?</h1> <p>A major challenge in pruning is determining what to prune. If you are removing weights or nodes from a model, you want the parameters you remove to be less useful. There are different heuristics and methods of determining which nodes are less important and can be removed with minimal effect on accuracy. You can use heuristics based on the weights or activations of a neuron to determine how important it is for the model‚Äôs performance. The goal is to remove more of the less important parameters.</p> <p>One of the simplest ways to prune is based on the magnitude of the weight. Removing a weight is essentially setting it to zero. You can minimize the effect on the network by removing weights that are already close to zero, meaning low in magnitude. This can be implemented by removing all weights below a certain threshold. To prune a neuron based on weight magnitude you can use the L2 norm of the neuron‚Äôs weights.</p> <p>Rather than just weights, activations on training data can be used as a criteria for pruning. When running a dataset through a network, certain statistics of the activations can be observed. You may observe that some neurons always outputs near-zero values. Those neurons can likely be removed with little impact on the model. The intuition is that if a neuron rarely activates with a high value, then it is rarely used in the model‚Äôs task.</p> <p>In addition to the magnitude of weights or activations, redundancy of parameters can mean a neuron can be removed. If two neurons in a layer have very similar weights or activations, it can mean they are doing the same thing. By this intuition, we can remove one of the neurons and preserve the same functionality.</p> <p>Ideally in a neural network, all the neurons have unique parameters and output activations that are significant in magnitude and not redundant. We want all the neurons are doing something unique, and remove those that are not.</p> <h1 id="when-to-prune">When to prune?</h1> <p>A major consideration in pruning is where to put it in the training/testing machine learning timeline. If you are using a weight magnitude-based pruning approach, as described in the previous section, you would want to prune after training. However, after pruning, you may observe that the model performance has suffered. This can be fixed by fine-tuning, meaning retraining the model after pruning to restore accuracy.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/assets/img/blog/pruning/pruning_flow-480.webp 480w,/blog/assets/img/blog/pruning/pruning_flow-800.webp 800w,/blog/assets/img/blog/pruning/pruning_flow-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/blog/assets/img/blog/pruning/pruning_flow.png" width="300" height="auto" alt="flow of iterative pruning" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption"> <a href="https://arxiv.org/abs/1611.06440" rel="external nofollow noopener" target="_blank"> Source </a> </figcaption> </figure> <p>The usage of pruning can change depending on the application and methods used. Sometimes fine-tuning or multiple iterations of pruning are not necessary. This depends on how much of the network is pruned.</p> <h1 id="how-to-evaluate-pruning">How to evaluate pruning?</h1> <p>There multiple metrics to consider when evaluating a pruning method: accuracy, size, and computation time. Accuracy is needed to determine how the model performs on its task. Model size is how much bytes of storage the model takes. To determine computation time, you can use FLOPs (Floating point operations) as a metric. This is more consistent to measure than inference time and it does not depend on what system the model runs on.</p> <p>With pruning, there is a tradeoff between model performance and efficiency. You can prune heavily and have a smaller more efficient network, but also less accurate. Or you could prune lightly and have a highly performant network, that is also large and expensive to operate. This trade-off needs to be considered for different applications of the neural network.</p> <h1 id="conclusion">Conclusion</h1> <p>Pruning is an effective method of making neural networks more efficient. There are plenty of choices and areas of research in this area. We want to continue to make advances in deep learning while also keeping our models energy, time, and space-efficient.</p> <h1 id="references">References</h1> <p>[1] Blalock, Davis, et al. ‚ÄúWhat is the state of neural network pruning?.‚Äù arXiv preprint arXiv:2003.03033 (2020).</p> <p>[2] Han, Song, et al. ‚ÄúLearning both weights and connections for efficient neural network.‚Äù Advances in neural information processing systems. 2015.</p> <p>[3] PyTorch Pruning Tutorial <a href="https://pytorch.org/tutorials/intermediate/pruning_tutorial.html" rel="external nofollow noopener" target="_blank">https://pytorch.org/tutorials/intermediate/pruning_tutorial.html</a></p> <p>[4] Keras / Tensorflow Pruning Tutorial <a href="https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras" rel="external nofollow noopener" target="_blank">https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras</a></p> <p>[5] Molchanov, Pavlo, et al. ‚ÄúPruning convolutional neural networks for resource efficient inference.‚Äù arXiv preprint arXiv:1611.06440 (2016).</p> <p>[6] Babaeizadeh, Mohammad, Paris Smaragdis, and Roy H. Campbell. ‚ÄúNoiseout: A simple way to prune neural networks.‚Äù arXiv preprint arXiv:1611.06211 (2016).</p> </div> </article> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2024 Rohit Bandaru. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?3e7054dc4d3e3dd8f0731a48453e618e"></script> <script defer src="/blog/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/blog/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/blog/assets/js/copy_code.js?3577194613afa04501eb52f8f4164de9" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-X48NHDB5RV"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-X48NHDB5RV");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-blog",title:"blog",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-about",title:"about",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/about/"}},{id:"post-transformer-design-guide-part-1-vanilla",title:"Transformer Design Guide (Part 1: Vanilla)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/Transformer-Design-Guide-Pt1/"}},{id:"post-self-supervision-from-videos",title:"Self-Supervision from Videos",description:"",section:"Posts",handler:()=>{window.location.href="/blog/Self-Supervision-from-Videos/"}},{id:"post-ssl-with-vision-transformers",title:"SSL with Vision Transformers",description:"",section:"Posts",handler:()=>{window.location.href="/blog/SSL-with-Vision-Transformers/"}},{id:"post-deep-dive-into-yann-lecun-s-jepa",title:"Deep Dive into Yann LeCun\u2019s JEPA",description:"",section:"Posts",handler:()=>{window.location.href="/blog/JEPA-Deep-Dive/"}},{id:"post-scaling-deep-learning",title:"Scaling Deep Learning",description:"",section:"Posts",handler:()=>{window.location.href="/blog/Scaling-Deep-Learning/"}},{id:"post-knowledge-distillation-as-self-supervised-learning",title:"Knowledge Distillation as Self-Supervised Learning",description:"",section:"Posts",handler:()=>{window.location.href="/blog/knowledge-distillation-ssl/"}},{id:"post-self-supervised-learning-getting-more-out-of-data",title:"Self-Supervised Learning\u200a -\u200a Getting more out of\xa0data",description:"",section:"Posts",handler:()=>{window.location.href="/blog/Self-Supervised-Learning/"}},{id:"post-domain-adaptation",title:"Domain Adaptation",description:"",section:"Posts",handler:()=>{window.location.href="/blog/Domain-Adaptation/"}},{id:"post-pruning-neural-networks",title:"Pruning Neural Networks",description:"",section:"Posts",handler:()=>{window.location.href="/blog/Neural-Network-Pruning/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%72%6F%68.%62%61%6E%64%61%72%75@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/rohit-bandaru","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/rohit_bandaru","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/blog/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>